spring.application.name=kunsharedemo

management.server.port=10001
management.server.servlet.context-path=/${spring.application.name}
#开启所有端点的访问
management.endpoints.web.exposure.include=*

nbaplay.number=1
nbaplay.level=super star

# Batch
spring.batch.job.enabled=false

# Spring Cloud Task
# 禁用Spring Cloud Task自动建表
#spring.cloud.task.initialize.enable=false
# task执行完毕后关闭上下文（一般不需要这样的操作）
#spring.cloud.task.closecontext_enabled=true
# 禁用Spring Cloud Task自动配置
#spring.cloud.task.autoconfiguration.enabled=false
#spring.cloud.task.batch.listener.enable=false

# 加一层自定义的开发，控制是否启用@EnableTask注解
#kunsharedemo.springcloud-task.enabled=false

# 是否开启手动数据源
# 只有多数据源时才需要开启，否则用自动配置的足够了，所以默认禁用
#kunsharedemo.maindb.datasource.enabled=false
kunsharedemo.maindb.datasource.enabled=true

# 应用主库（quartz专用的数据源）
spring.datasource.quartzDataSource.driverClassName=com.mysql.jdbc.Driver
spring.datasource.quartzDataSource.url=jdbc:mysql://192.168.3.104:3306/test?useUnicode=true&characterEncoding=utf-8
spring.datasource.quartzDataSource.username=root
spring.datasource.quartzDataSource.password=12345678
spring.datasource.quartzDataSource.type=com.alibaba.druid.pool.DruidDataSource

# 连接池的配置信息
# 初始化大小，最小，最大
spring.datasource.quartzDataSource.initialSize=5
spring.datasource.quartzDataSource.minIdle=5
spring.datasource.quartzDataSource.maxActive=20
# 配置获取连接等待超时的时间
spring.datasource.quartzDataSource.maxWait=60000
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
spring.datasource.quartzDataSource.timeBetweenEvictionRunsMillis=60000
# 配置一个连接在池中最小生存的时间，单位是毫秒
spring.datasource.quartzDataSource.minEvictableIdleTimeMillis=300000
spring.datasource.quartzDataSource.validationQuery=SELECT 1 FROM DUAL
spring.datasource.quartzDataSource.testWhileIdle=true
spring.datasource.quartzDataSource.testOnBorrow=false
spring.datasource.quartzDataSource.testOnReturn=false
# 打开PSCache，并且指定每个连接上PSCache的大小
spring.datasource.quartzDataSource.poolPreparedStatements=true
spring.datasource.quartzDataSource.maxPoolPreparedStatementPerConnectionSize=20
# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
spring.datasource.quartzDataSource.filters=stat,wall,log4j
# 通过connectProperties属性来打开mergeSql功能；慢SQL记录
spring.datasource.quartzDataSource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000

#是否启用fastjson做全局json转换器
kunsharedemo.fastjson.enabled=false

# redis（单节点模式）
#spring.redis.host=127.0.0.1
#spring.redis.password=
#spring.redis.port=6379

## spring session
#spring.session.store-type=redis
spring.session.store-type=none
# Session 过期时间，单位s（用默认的即可）
#server.session.timeout=600
# Sessions 刷新模式
spring.session.redis.flush-mode=IMMEDIATE
# Namespace for keys used to store sessions.
spring.session.redis.namespace=spring:session:kunsharedemo

# 自定义开关：控制@EnableRedisHttpSession是否生效
kunsharedemo.redis-session.enabled=false
# 通过排除自动配置的方式禁用spring session（不推荐）
#spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.session.SessionAutoConfiguration

# 排除Quartz（禁用Quartz）
spring.autoconfigure.exclude=org.springframework.boot.autoconfigure.quartz.QuartzAutoConfiguration
kunsharedemo.quartz.enabled=false


# 自定义开关：控制Jedis是否生效
kunsharedemo.jedis.enabled=false
# 引入jedis
spring.jedis.pool.host=127.0.0.1
spring.jedis.pool.password=
spring.jedis.pool.port=6379
spring.jedis.pool.minIdle=10
spring.jedis.pool.maxIdle = 20
spring.jedis.pool.maxTotal = 500
spring.jedis.pool.numTestsPerEvictionRun = 3
spring.jedis.pool.testOnBorrow = true
spring.jedis.pool.blockWhenExhausted = false
spring.jedis.pool.testOnReturn = false


#============== kafka ===================
# 指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=192.168.3.105-------------------:9092
spring.kafka.listener.missing-topics-fatal=false

#=============== provider  =======================
spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432

# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer



#=============== consumer  =======================
# 指定默认消费者group id
spring.kafka.consumer.group-id=test-hello-group

spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true